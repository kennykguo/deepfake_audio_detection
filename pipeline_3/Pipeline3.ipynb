{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JZvUxEuIrOup"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def temporal_alignment(input):\n",
        "\n",
        "  # Input: (B, 500, 512)\n",
        "  B, time, feature = input.shape\n",
        "  output = np.zeros((B, 250, feature))\n",
        "\n",
        "  # For each target frame t in range 0-249:\n",
        "  for t in range(250):\n",
        "    # output[t] = (input[2t] + input[2t+1]) / 2\n",
        "    output[:, t, :] = (input[:, 2*t, :] + input[:, 2*t+1, :]) / 2\n",
        "\n",
        "  return output\n",
        "\n",
        "def dimension_alightment(wav2vec, xlsr, whisper):\n",
        "\n",
        "  # Linear projections:\n",
        "  # Wav2Vec: (B, 250, 768)  → (B, 250, 512)\n",
        "  # XLSR: (B, 250, 1024) → (B, 250, 512)\n",
        "  # Whisper: (B, 250, 512)\n",
        "  wav2vec_linear = torch.nn.Linear(768, 512)\n",
        "  xlsr_linear = torch.nn.Linear(1024, 512)\n",
        "\n",
        "  wav2vec_output = wav2vec_linear(wav2vec)\n",
        "  xlsr_output = xlsr_linear(xlsr)\n",
        "\n",
        "  return (wav2vec_output, xlsr_output, whisper)\n",
        "\n",
        "\n",
        "wav2vec = #wav2vec encoder\n",
        "xlsr = #xlsr encoder\n",
        "whisper = #whisper encoder\n",
        "\n",
        "whisper = temporal_alignment(whisper)\n",
        "\n",
        "# save the output first\n",
        "output = (wav2vec, xlsr, whisper)\n",
        "# linear projections\n",
        "projections = dimension_alightment(wav2vec, xlsr, whisper)\n",
        "\n"
      ]
    }
  ]
}